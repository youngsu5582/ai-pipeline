#!/usr/bin/env python3
"""
AI Pipeline - Document Vacuum
=============================
í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ í©ì–´ì§„ MD íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ docs/ë¡œ ì •ë¦¬

Usage:
    python vacuum.py /path/to/project [--dry-run] [--auto] [--to-obsidian] [--json]

Examples:
    vacuum ~/Projects/my-project --dry-run    # ë¯¸ë¦¬ë³´ê¸°ë§Œ
    vacuum ~/Projects/my-project --auto       # í™•ì¸ ì—†ì´ ì¦‰ì‹œ ì‹¤í–‰
    vacuum ~/Projects/my-project --auto --to-obsidian  # ìë™ ì‹¤í–‰ + Obsidian ë³µì‚¬
"""

import argparse
import json
import re
import shutil
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

import yaml

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ config ë¡œë“œ
CONFIG_PATH = Path(__file__).parent.parent / "config" / "settings.yaml"


def load_config() -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


CONFIG = load_config()

# ì œì™¸í•  íŒŒì¼ íŒ¨í„´
EXCLUDE_PATTERNS = [
    "README*.md",
    "CLAUDE.md",
    "AGENTS.md",
    "LICENSE*.md",
    "CHANGELOG*.md",
    "CONTRIBUTING*.md",
]

# ì œì™¸í•  ë””ë ‰í† ë¦¬
EXCLUDE_DIRS = [
    "node_modules",
    "docs",
    ".claude",
    ".git",
    "target",
    "build",
    "dist",
    ".gradle",
    ".idea",
    "venv",
    ".venv",
]

# ë¬¸ì„œ ìœ í˜• ë¶„ë¥˜ ê·œì¹™ (íŒ¨í„´ -> ìœ í˜•)
DOC_TYPE_RULES = {
    "spec": [
        r"ëª…ì„¸",
        r"SPEC",
        r"##\s*ë³€ê²½\s*ë²”ìœ„",
        r"ì¸í„°í˜ì´ìŠ¤\s*ì •ì˜",
        r"API\s*ìŠ¤í™",
        r"ê³„ì•½\s*ì •ì˜",
    ],
    "implementation": [
        r"êµ¬í˜„\s*ê³„íš",
        r"Task\s*\d+:",
        r"\*\*Path\*\*:",
        r"êµ¬í˜„\s*ìƒì„¸",
        r"Implementation\s*Plan",
        r"##\s*êµ¬í˜„\s*ìˆœì„œ",
    ],
    "learning": [
        r"##\s*ëª©ì°¨",
        r"ì™„ë²½\s*ì •ë¦¬",
        r"ê°€ì´ë“œ",
        r"Deep\s*Dive",
        r"í•µì‹¬\s*ê°œë…",
        r"##\s*í•™ìŠµ",
        r"Tutorial",
    ],
    "issue": [
        r"PROJECT-KEY-\d+",
        r"ë²„ê·¸\s*ìˆ˜ì •",
        r"ë¬¸ì œ\s*ìƒí™©",
        r"ì´ìŠˆ\s*ë¶„ì„",
        r"Bug\s*Fix",
        r"##\s*ì›ì¸\s*ë¶„ì„",
    ],
    "testing": [
        r"E2E.*í…ŒìŠ¤íŠ¸",
        r"í…ŒìŠ¤íŠ¸\s*ì‹œë‚˜ë¦¬ì˜¤",
        r"í…ŒìŠ¤íŠ¸\s*ê³„íš",
        r"Test\s*Plan",
        r"í…ŒìŠ¤íŠ¸\s*ì¼€ì´ìŠ¤",
    ],
    "review": [
        r"ë¦¬ë·°",
        r"ì½”ë“œ\s*ë¦¬ë·°",
        r"PR\s*ë¦¬ë·°",
        r"Code\s*Review",
    ],
}

# ëŒ€ìƒ í´ë” ë§¤í•‘
TARGET_FOLDERS = {
    "spec": "docs/specs",
    "implementation": "docs/implementation",
    "learning": "docs/learning",
    "issue": "docs/issues/drafts",
    "testing": "docs/testing",
    "review": "docs/reviews",
}

# ê¸°ìˆ  ìŠ¤íƒ íƒœê·¸ ê·œì¹™
TECH_TAGS = {
    "postgresql": [r"postgresql", r"postgres", r"prepared\s*statement", r"partition", r"pgvector"],
    "kafka": [r"kafka", r"consumer", r"producer", r"topic(?!s?\s*:)", r"partition"],
    "spring": [r"spring", r"@bean", r"@service", r"jpa", r"@transactional", r"springboot"],
    "aws": [r"aws", r"\bs3\b", r"lambda", r"cloudfront", r"\bec2\b", r"dynamodb"],
    "redis": [r"redis", r"cache", r"pub/sub"],
    "rabbitmq": [r"rabbitmq", r"amqp", r"message\s*queue"],
    "react": [r"react", r"component", r"hooks", r"\.tsx"],
    "docker": [r"docker", r"container", r"dockerfile", r"compose"],
    "java": [r"java", r"\.java", r"gradle", r"maven"],
    "typescript": [r"typescript", r"\.ts", r"type\s*:"],
}


def should_exclude_file(file_path: Path) -> bool:
    """íŒŒì¼ ì œì™¸ ì—¬ë¶€ í™•ì¸"""
    name = file_path.name

    for pattern in EXCLUDE_PATTERNS:
        if pattern.startswith("*"):
            if name.endswith(pattern[1:]):
                return True
        elif pattern.endswith("*"):
            if name.startswith(pattern[:-1]):
                return True
        elif "*" in pattern:
            import fnmatch
            if fnmatch.fnmatch(name, pattern):
                return True
        elif name == pattern:
            return True

    return False


def should_exclude_dir(dir_path: Path) -> bool:
    """ë””ë ‰í† ë¦¬ ì œì™¸ ì—¬ë¶€ í™•ì¸"""
    parts = dir_path.parts
    return any(excluded in parts for excluded in EXCLUDE_DIRS)


def find_md_files(project_root: Path, recursive: bool = False) -> list[Path]:
    """í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì •ë¦¬ ëŒ€ìƒ MD íŒŒì¼ íƒìƒ‰

    Args:
        project_root: íƒìƒ‰í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        recursive: Trueë©´ í•˜ìœ„ ë””ë ‰í† ë¦¬ë„ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰
    """
    md_files = []

    if recursive:
        # ì¬ê·€ì  íƒìƒ‰ (ì œì™¸ ë””ë ‰í† ë¦¬ ì œì™¸)
        for md_file in project_root.rglob("*.md"):
            if should_exclude_dir(md_file.parent):
                continue
            if not should_exclude_file(md_file):
                md_files.append(md_file)
    else:
        # í˜„ì¬ ë””ë ‰í† ë¦¬ë§Œ íƒìƒ‰
        for md_file in project_root.glob("*.md"):
            if not should_exclude_file(md_file):
                md_files.append(md_file)

    return sorted(md_files, key=lambda f: f.stat().st_mtime, reverse=True)


def read_file_content(file_path: Path, max_chars: int = 10000) -> str:
    """íŒŒì¼ ë‚´ìš© ì½ê¸° (ìµœëŒ€ ë¬¸ì ìˆ˜ ì œí•œ)"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read(max_chars)
    except Exception as e:
        return ""


def extract_title(content: str, file_path: Path) -> str:
    """ì œëª© ì¶”ì¶œ"""
    # ì²« ë²ˆì§¸ # í—¤ë” ì°¾ê¸°
    match = re.search(r"^#\s+(.+)$", content, re.MULTILINE)
    if match:
        return match.group(1).strip()

    # íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
    return file_path.stem.replace("-", " ").replace("_", " ").title()


def classify_doc_type(content: str) -> str:
    """ë¬¸ì„œ ìœ í˜• ë¶„ë¥˜"""
    content_lower = content.lower()

    scores = {doc_type: 0 for doc_type in DOC_TYPE_RULES}

    for doc_type, patterns in DOC_TYPE_RULES.items():
        for pattern in patterns:
            if re.search(pattern, content, re.IGNORECASE):
                scores[doc_type] += 1

    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ìœ í˜• ë°˜í™˜
    max_score = max(scores.values())
    if max_score > 0:
        for doc_type, score in scores.items():
            if score == max_score:
                return doc_type

    return "learning"  # ê¸°ë³¸ê°’


def extract_tech_tags(content: str) -> list[str]:
    """ê¸°ìˆ  ìŠ¤íƒ íƒœê·¸ ì¶”ì¶œ"""
    tags = []
    content_lower = content.lower()

    for tag, patterns in TECH_TAGS.items():
        for pattern in patterns:
            if re.search(pattern, content_lower, re.IGNORECASE):
                tags.append(tag)
                break

    return tags


def extract_summary(content: str, max_length: int = 200) -> str:
    """ë¬¸ì„œ ìš”ì•½ ì¶”ì¶œ"""
    # frontmatter ì œê±°
    content = re.sub(r"^---.*?---\s*", "", content, flags=re.DOTALL)

    # ì²« ë²ˆì§¸ í—¤ë” ì´í›„ ì²« ë‹¨ë½ ì¶”ì¶œ
    lines = content.strip().split("\n")
    summary_lines = []
    in_paragraph = False

    for line in lines:
        stripped = line.strip()
        if stripped.startswith("#"):
            if in_paragraph:
                break
            continue
        if stripped and not stripped.startswith(("```", "---", "|", "-", "*", ">")):
            summary_lines.append(stripped)
            in_paragraph = True
            if len(" ".join(summary_lines)) >= max_length:
                break
        elif in_paragraph and not stripped:
            break

    summary = " ".join(summary_lines)
    if len(summary) > max_length:
        summary = summary[:max_length] + "..."

    return summary


def normalize_filename(title: str, date: str) -> str:
    """íŒŒì¼ëª… ì •ê·œí™”"""
    # íŠ¹ìˆ˜ë¬¸ì ì œê±°, ê³µë°±ì„ í•˜ì´í”ˆìœ¼ë¡œ
    normalized = re.sub(r"[^\w\sê°€-í£-]", "", title)
    normalized = re.sub(r"\s+", "-", normalized.strip())
    normalized = normalized.lower()

    # ë„ˆë¬´ ê¸´ íŒŒì¼ëª… ì¤„ì´ê¸°
    if len(normalized) > 50:
        normalized = normalized[:50]

    return f"{date}_{normalized}.md"


def has_frontmatter(content: str) -> bool:
    """YAML frontmatter ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    return content.strip().startswith("---")


def create_frontmatter(title: str, doc_type: str, tags: list[str], original_file: str) -> str:
    """YAML frontmatter ìƒì„±"""
    today = datetime.now().strftime("%Y-%m-%d")

    frontmatter = f"""---
title: "{title}"
date: {today}
category: {doc_type}
tags: [{", ".join(tags)}]
source: claude-session
status: draft
original_file: {original_file}
---

"""
    return frontmatter


def analyze_file(file_path: Path) -> dict:
    """íŒŒì¼ ë¶„ì„"""
    content = read_file_content(file_path)

    title = extract_title(content, file_path)
    doc_type = classify_doc_type(content)
    tags = extract_tech_tags(content)
    summary = extract_summary(content)
    has_fm = has_frontmatter(content)

    today = datetime.now().strftime("%Y-%m-%d")
    new_filename = normalize_filename(title, today)
    target_folder = TARGET_FOLDERS.get(doc_type, "docs/learning")
    target_path = f"{target_folder}/{new_filename}"

    return {
        "original_path": str(file_path),
        "original_name": file_path.name,
        "title": title,
        "doc_type": doc_type,
        "tags": tags,
        "summary": summary,
        "target_path": target_path,
        "has_frontmatter": has_fm,
        "size_kb": round(file_path.stat().st_size / 1024, 1),
    }


def move_file(analysis: dict, project_root: Path, add_frontmatter: bool = True) -> bool:
    """íŒŒì¼ ì´ë™ ë° frontmatter ì¶”ê°€"""
    original_path = Path(analysis["original_path"])
    target_path = project_root / analysis["target_path"]

    # ëŒ€ìƒ í´ë” ìƒì„±
    target_path.parent.mkdir(parents=True, exist_ok=True)

    # ë‚´ìš© ì½ê¸°
    with open(original_path, "r", encoding="utf-8") as f:
        content = f.read()

    # frontmatter ì¶”ê°€ (ì—†ëŠ” ê²½ìš°)
    if add_frontmatter and not analysis["has_frontmatter"]:
        frontmatter = create_frontmatter(
            analysis["title"],
            analysis["doc_type"],
            analysis["tags"],
            analysis["original_name"]
        )
        content = frontmatter + content

    # ëŒ€ìƒ ê²½ë¡œì— ì“°ê¸°
    with open(target_path, "w", encoding="utf-8") as f:
        f.write(content)

    # ì›ë³¸ ì‚­ì œ
    original_path.unlink()

    return True


def get_obsidian_path(analysis: dict) -> Path:
    """ë¶„ì„ ê²°ê³¼ì— ë”°ë¥¸ Obsidian ëŒ€ìƒ ê²½ë¡œ ê³„ì‚°"""
    vault_path = Path(CONFIG["vault"]["path"])
    target_folder = CONFIG["vault"].get("target_folder", "study")

    # vacuum ì„¤ì •ì—ì„œ Obsidian í´ë” ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°
    vacuum_config = CONFIG.get("vacuum", {})
    obsidian_folders = vacuum_config.get("obsidian_folders", {
        "spec": "projects/aicreation/specs",
        "implementation": "projects/aicreation/implementation",
        "learning": "projects/aicreation/learning",
        "issue": "projects/aicreation/issues",
        "testing": "projects/aicreation/testing",
        "review": "projects/aicreation/reviews",
    })

    category = analysis["doc_type"]
    relative_folder = obsidian_folders.get(category, "_inbox")
    obsidian_folder = vault_path / target_folder / relative_folder

    # íŒŒì¼ëª… ì¶”ì¶œ
    filename = Path(analysis["target_path"]).name
    return obsidian_folder / filename


def move_to_obsidian(analysis: dict, add_frontmatter: bool = True) -> Optional[str]:
    """ì›ë³¸ íŒŒì¼ì„ Obsidian vaultë¡œ ì§ì ‘ ì´ë™ (í”„ë¡œì íŠ¸ì— ë‚¨ê¸°ì§€ ì•ŠìŒ)"""
    original_path = Path(analysis["original_path"])
    obsidian_path = get_obsidian_path(analysis)

    # ëŒ€ìƒ í´ë” ìƒì„±
    obsidian_path.parent.mkdir(parents=True, exist_ok=True)

    # ë‚´ìš© ì½ê¸°
    with open(original_path, "r", encoding="utf-8") as f:
        content = f.read()

    # frontmatter ì¶”ê°€ (ì—†ëŠ” ê²½ìš°)
    if add_frontmatter and not analysis["has_frontmatter"]:
        frontmatter = create_frontmatter(
            analysis["title"],
            analysis["doc_type"],
            analysis["tags"],
            analysis["original_name"]
        )
        content = frontmatter + content

    # Obsidianì— ì“°ê¸°
    with open(obsidian_path, "w", encoding="utf-8") as f:
        f.write(content)

    # ì›ë³¸ ì‚­ì œ
    original_path.unlink()

    return str(obsidian_path)


def copy_to_obsidian(analysis: dict, project_root: Path) -> Optional[str]:
    """Obsidian vaultë¡œ ë³µì‚¬ (docs/ì—ë„ ìœ ì§€)"""
    obsidian_path = get_obsidian_path(analysis)
    obsidian_path.parent.mkdir(parents=True, exist_ok=True)

    # ì†ŒìŠ¤ íŒŒì¼ ê²½ë¡œ (ì´ë¯¸ docs/ë¡œ ì´ë™ëœ íŒŒì¼)
    source_path = project_root / analysis["target_path"]

    if source_path.exists():
        shutil.copy2(source_path, obsidian_path)
        return str(obsidian_path)

    return None


def format_preview_markdown(analyses: list[dict]) -> str:
    """ë¯¸ë¦¬ë³´ê¸° ë§ˆí¬ë‹¤ìš´ ìƒì„±"""
    lines = ["# Vacuum ë¯¸ë¦¬ë³´ê¸°", "", f"## ë°œê²¬ëœ íŒŒì¼ ({len(analyses)}ê°œ)", ""]

    for i, analysis in enumerate(analyses, 1):
        lines.extend([
            f"### {i}. {analysis['original_name']}",
            f"- [x] ì²˜ë¦¬",
            f"- **ìœ í˜•**: {analysis['doc_type']}",
            f"- **íƒœê·¸**: {', '.join(analysis['tags']) or 'ì—†ìŒ'}",
            f"- **ëŒ€ìƒ**: `{analysis['target_path']}`",
            f"- **í¬ê¸°**: {analysis['size_kb']}KB",
            "",
            f"> {analysis['summary'][:200]}{'...' if len(analysis['summary']) > 200 else ''}",
            "",
            "---",
            ""
        ])

    lines.extend([
        "## ìˆ˜ì • ë°©ë²•",
        "ì½”ë©˜íŠ¸ë¡œ ìˆ˜ì • ìš”ì²­:",
        "- `title: ìƒˆ ì œëª©` - ì œëª© ë³€ê²½",
        "- `folder: docs/other/` - ëŒ€ìƒ í´ë” ë³€ê²½",
        "- `tags: +newtag` - íƒœê·¸ ì¶”ê°€",
        "- `skip` - ê±´ë„ˆë›°ê¸°",
    ])

    return "\n".join(lines)


def format_result_report(moved: list[dict], skipped: list[dict], total: int) -> str:
    """ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
    lines = [
        "# Vacuum ì™„ë£Œ",
        "",
        "## ì²˜ë¦¬ ê²°ê³¼",
        f"- ì´ {total}ê°œ íŒŒì¼ ë°œê²¬",
        f"- {len(moved)}ê°œ íŒŒì¼ ì´ë™ ì™„ë£Œ",
        f"- {len(skipped)}ê°œ íŒŒì¼ ê±´ë„ˆëœ€",
        "",
    ]

    if moved:
        lines.extend(["## ì´ë™ëœ íŒŒì¼", "", "| ì›ë³¸ | ëŒ€ìƒ | ìœ í˜• |", "|------|------|------|"])
        for item in moved:
            lines.append(f"| {item['original_name']} | {item['target_path']} | {item['doc_type']} |")
        lines.append("")

    lines.extend([
        "## ë‹¤ìŒ ë‹¨ê³„",
        "- `git add docs/` ë¡œ ë³€ê²½ì‚¬í•­ ìŠ¤í…Œì´ì§•",
        "- `vacuum --to-obsidian` ìœ¼ë¡œ Obsidian vaultì—ë„ ë³µì‚¬ ê°€ëŠ¥",
    ])

    return "\n".join(lines)


def prompt_confirmation(analyses: list[dict]) -> bool:
    """ì‚¬ìš©ì í™•ì¸ í”„ë¡¬í”„íŠ¸"""
    print(format_preview_markdown(analyses))
    print("\n" + "â”" * 50)
    try:
        response = input("ìœ„ íŒŒì¼ë“¤ì„ ì •ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ? [y/N]: ").strip().lower()
        return response in ("y", "yes")
    except (EOFError, KeyboardInterrupt):
        return False


def get_default_options() -> dict:
    """ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ ì˜µì…˜ ë¡œë“œ"""
    vacuum_config = CONFIG.get("vacuum", {})
    defaults = vacuum_config.get("defaults", {})
    return {
        "auto": defaults.get("auto", False),
        "to_obsidian": defaults.get("to_obsidian", False),
    }


def main():
    # ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ê°’ ë¡œë“œ
    defaults = get_default_options()

    parser = argparse.ArgumentParser(
        description="Document Vacuum - í©ì–´ì§„ MD íŒŒì¼ ì •ë¦¬",
        epilog="ê¸°ë³¸ê°’: --auto={}, --to-obsidian={} (settings.yamlì—ì„œ ë³€ê²½ ê°€ëŠ¥)".format(
            defaults["auto"], defaults["to_obsidian"]
        )
    )
    parser.add_argument("project", nargs="?", default=".", help="í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ")
    parser.add_argument("--paths", help="ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì¶”ê°€ íƒìƒ‰ ê²½ë¡œ (ì˜ˆ: docs/specs,docs/issues)")
    parser.add_argument("--recursive", "-r", action="store_true", help="í•˜ìœ„ ë””ë ‰í† ë¦¬ë„ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰")
    parser.add_argument("--dry-run", action="store_true", help="ì‹¤ì œ ì´ë™ ì—†ì´ ë¶„ì„ë§Œ")
    parser.add_argument("--auto", action="store_true", default=defaults["auto"],
                        help="í™•ì¸ ì—†ì´ ì¦‰ì‹œ ì‹¤í–‰ (ê¸°ë³¸: {})".format(defaults["auto"]))
    parser.add_argument("--no-auto", action="store_true", help="--auto ë¹„í™œì„±í™” (í™•ì¸ ë°›ê¸°)")
    parser.add_argument("--to-obsidian", action="store_true", default=defaults["to_obsidian"],
                        help="Obsidian vaultë¡œë„ ë³µì‚¬ (ê¸°ë³¸: {})".format(defaults["to_obsidian"]))
    parser.add_argument("--no-obsidian", action="store_true", help="--to-obsidian ë¹„í™œì„±í™”")
    parser.add_argument("--json", action="store_true", help="JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥")
    parser.add_argument("--pattern", help="íŒŒì¼ íŒ¨í„´ (ì˜ˆ: PostgreSQL*.md)")
    parser.add_argument("--exclude", help="ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì œì™¸ íŒ¨í„´ (ì˜ˆ: README*.md,CHANGELOG*.md)")
    parser.add_argument("--quiet", "-q", action="store_true", help="ìµœì†Œ ì¶œë ¥ (ìŠ¤í¬ë¦½íŠ¸ ì—°ë™ìš©)")

    args = parser.parse_args()

    # --no-* í”Œë˜ê·¸ë¡œ ê¸°ë³¸ê°’ ì˜¤ë²„ë¼ì´ë“œ
    if args.no_auto:
        args.auto = False
    if args.no_obsidian:
        args.to_obsidian = False

    project_root = Path(args.project).resolve()

    if not project_root.exists():
        print(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {project_root}")
        sys.exit(1)

    # íƒìƒ‰í•  ê²½ë¡œ ëª©ë¡ êµ¬ì„±
    search_paths = [project_root]

    # --paths ì˜µì…˜ìœ¼ë¡œ ì¶”ê°€ ê²½ë¡œ ì§€ì •
    if args.paths:
        for path_str in args.paths.split(","):
            path_str = path_str.strip()
            if not path_str:
                continue
            # ìƒëŒ€ ê²½ë¡œë©´ project_root ê¸°ì¤€ìœ¼ë¡œ í•´ì„
            if not path_str.startswith("/"):
                extra_path = project_root / path_str
            else:
                extra_path = Path(path_str)
            if extra_path.exists() and extra_path.is_dir():
                search_paths.append(extra_path.resolve())
            elif not args.quiet:
                print(f"âš ï¸  ê²½ë¡œ ì—†ìŒ: {path_str}")

    # MD íŒŒì¼ íƒìƒ‰ (ëª¨ë“  ê²½ë¡œì—ì„œ)
    md_files = []
    seen_paths = set()  # ì¤‘ë³µ ë°©ì§€

    for search_path in search_paths:
        for md_file in find_md_files(search_path, recursive=args.recursive):
            if md_file not in seen_paths:
                seen_paths.add(md_file)
                md_files.append(md_file)

    # ìˆ˜ì •ì¼ ê¸°ì¤€ ì •ë ¬
    md_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)

    # íŒ¨í„´ í•„í„°ë§ (í¬í•¨)
    if args.pattern:
        import fnmatch
        md_files = [f for f in md_files if fnmatch.fnmatch(f.name, args.pattern)]

    # ì œì™¸ íŒ¨í„´ í•„í„°ë§
    if args.exclude:
        import fnmatch
        exclude_patterns = [p.strip() for p in args.exclude.split(",") if p.strip()]
        filtered = []
        for f in md_files:
            excluded = False
            for pattern in exclude_patterns:
                if fnmatch.fnmatch(f.name, pattern):
                    excluded = True
                    break
            if not excluded:
                filtered.append(f)
        md_files = filtered

    if not md_files:
        if not args.quiet:
            print("ğŸ“­ ì •ë¦¬í•  MD íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(0)

    # íŒŒì¼ ë¶„ì„
    analyses = [analyze_file(f) for f in md_files]

    # JSON ì¶œë ¥
    if args.json:
        print(json.dumps(analyses, ensure_ascii=False, indent=2))
        sys.exit(0)

    # Dry-run: ë¯¸ë¦¬ë³´ê¸°ë§Œ ì¶œë ¥
    if args.dry_run:
        print(format_preview_markdown(analyses))
        sys.exit(0)

    # ìë™ ëª¨ë“œê°€ ì•„ë‹ˆë©´ í™•ì¸ ë°›ê¸°
    if not args.auto:
        if not prompt_confirmation(analyses):
            print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            sys.exit(0)

    # ì‹¤ì œ ì´ë™
    moved = []
    skipped = []

    if not args.quiet:
        print("â”" * 50)
        print("ğŸ§¹ Vacuum - ë¬¸ì„œ ì •ë¦¬ ì‹œì‘")
        print("â”" * 50)

    for analysis in analyses:
        try:
            if args.to_obsidian:
                # Obsidianìœ¼ë¡œ ì§ì ‘ ì´ë™ (docs/ì— ë‚¨ê¸°ì§€ ì•ŠìŒ)
                obsidian_path = move_to_obsidian(analysis)
                moved.append(analysis)
                if not args.quiet:
                    print(f"âœ… {analysis['original_name']} â†’ {obsidian_path}")
            else:
                # ê¸°ë³¸: docs/ë¡œ ì´ë™
                move_file(analysis, project_root)
                moved.append(analysis)
                if not args.quiet:
                    print(f"âœ… {analysis['original_name']} â†’ {analysis['target_path']}")
        except Exception as e:
            skipped.append(analysis)
            if not args.quiet:
                print(f"âŒ {analysis['original_name']}: {e}")

    if not args.quiet:
        print("â”" * 50)
        print(f"\n{format_result_report(moved, skipped, len(analyses))}")
    else:
        # quiet ëª¨ë“œì—ì„œëŠ” í•œ ì¤„ ìš”ì•½ë§Œ
        print(f"Vacuum: {len(moved)} moved, {len(skipped)} skipped")


if __name__ == "__main__":
    main()
