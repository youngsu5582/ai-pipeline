#!/usr/bin/env python3
"""
AI Pipeline - RSS Feed Collector
=================================
RSS í”¼ë“œë¥¼ ìˆ˜ì§‘í•˜ì—¬ Obsidian reading í´ë”ì— ì €ì¥

Usage:
    python rss_collector.py                     # ì„¤ì • íŒŒì¼ í”¼ë“œ ìˆ˜ì§‘
    python rss_collector.py --yes               # ìë™ ì €ì¥
    python rss_collector.py --days 3            # ìµœê·¼ 3ì¼ ê¸€ë§Œ
    python rss_collector.py --feeds "url1,url2" # íŠ¹ì • í”¼ë“œë§Œ ìˆ˜ì§‘
    python rss_collector.py --skip-existing     # ì´ë¯¸ ìˆëŠ” ê¸€ ê±´ë„ˆë›°ê¸°

Options:
    --feeds URL,...    ì‰¼í‘œë¡œ êµ¬ë¶„ëœ RSS í”¼ë“œ URL ëª©ë¡
    --days N           ìµœê·¼ Nì¼ê°„ ê¸€ë§Œ ìˆ˜ì§‘ (ê¸°ë³¸: 7)
    --yes              í™•ì¸ ì—†ì´ ìë™ ì €ì¥
    --slack            Slack ì•Œë¦¼ ì „ì†¡
    --skip-existing    Obsidianì— ì´ë¯¸ ìˆëŠ” ê¸€ ê±´ë„ˆë›°ê¸° (ì„¤ì • íŒŒì¼ì—ì„œë„ ê°€ëŠ¥)
    --no-skip          ì¤‘ë³µ ë°©ì§€ ë¹„í™œì„±í™” (ì„¤ì • íŒŒì¼ ë®ì–´ì“°ê¸°)

Requirements:
    - feedparser ì„¤ì¹˜ (pip install feedparser)
    - config/settings.yamlì— rss.feeds ì„¤ì • (--feeds ë¯¸ì§€ì • ì‹œ)
"""

import json
import os
import sys
import urllib.request
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional
from email.utils import parsedate_to_datetime

try:
    import feedparser
except ImportError:
    print("âŒ feedparserê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    print("   pip install feedparser")
    sys.exit(1)

import yaml


CONFIG_PATH = Path(__file__).parent.parent / "config" / "settings.yaml"


def load_config() -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ (ìš°ì„ ìˆœìœ„ ì ìš©)"""
    config_files = [
        CONFIG_PATH.parent / "settings.local.yaml",
        CONFIG_PATH,
        CONFIG_PATH.parent / "settings.example.yaml",
    ]
    for config_file in config_files:
        if config_file.exists():
            with open(config_file, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
    return {}


CONFIG = load_config()


def get_rss_config() -> dict:
    """RSS ì„¤ì • ì¡°íšŒ"""
    return CONFIG.get("rss", {})


def get_feeds(override_urls: list[str] = None) -> list[dict]:
    """RSS í”¼ë“œ ëª©ë¡ ì¡°íšŒ

    Args:
        override_urls: ì˜µì…˜ìœ¼ë¡œ ì „ë‹¬ëœ URL ëª©ë¡ (ì„¤ì • íŒŒì¼ ëŒ€ì‹  ì‚¬ìš©)
    """
    # ì˜µì…˜ìœ¼ë¡œ í”¼ë“œ URLì´ ì „ë‹¬ëœ ê²½ìš°
    if override_urls:
        feeds = []
        for url in override_urls:
            url = url.strip()
            if not url:
                continue
            # URLì—ì„œ ì´ë¦„ ì¶”ì¶œ (ë„ë©”ì¸ ê¸°ì¤€)
            try:
                from urllib.parse import urlparse
                domain = urlparse(url).netloc
                name = domain.replace("www.", "").split(".")[0].title()
            except Exception:
                name = "Unknown"

            feeds.append({
                "url": url,
                "name": name,
                "category": "custom"
            })
        return feeds

    # ì„¤ì • íŒŒì¼ì—ì„œ ì¡°íšŒ
    rss_config = get_rss_config()
    feeds = rss_config.get("feeds", [])

    if not feeds:
        print("âš ï¸  RSS í”¼ë“œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   config/settings.yamlì— rss.feedsë¥¼ ì„¤ì •í•˜ê±°ë‚˜")
        print("   --feeds ì˜µì…˜ìœ¼ë¡œ URLì„ ì§€ì •í•˜ì„¸ìš”.")
        print("")
        print("   ì˜ˆì‹œ:")
        print("   rss:")
        print("     feeds:")
        print('       - url: "https://example.com/feed.xml"')
        print('         name: "Example Blog"')
        print('         category: "tech"')
        print("")
        print("   ë˜ëŠ”: python rss_collector.py --feeds \"https://blog.example.com/feed\"")
        return []

    return feeds


def parse_date(entry) -> Optional[datetime]:
    """RSS ì—”íŠ¸ë¦¬ì—ì„œ ë‚ ì§œ íŒŒì‹±"""
    # published_parsed, updated_parsed ë“± ì—¬ëŸ¬ í•„ë“œ ì‹œë„
    for field in ['published_parsed', 'updated_parsed', 'created_parsed']:
        if hasattr(entry, field) and getattr(entry, field):
            try:
                import time
                return datetime(*getattr(entry, field)[:6])
            except (TypeError, ValueError):
                pass

    # ë¬¸ìì—´ì—ì„œ ì§ì ‘ íŒŒì‹± ì‹œë„
    for field in ['published', 'updated', 'created']:
        if hasattr(entry, field) and getattr(entry, field):
            try:
                return parsedate_to_datetime(getattr(entry, field))
            except (TypeError, ValueError):
                pass

    return None


def fetch_feed(feed_config: dict, days: int = 7) -> list[dict]:
    """ë‹¨ì¼ í”¼ë“œ ìˆ˜ì§‘"""
    url = feed_config.get("url", "")
    name = feed_config.get("name", url)
    category = feed_config.get("category", "general")

    if not url:
        return []

    try:
        feed = feedparser.parse(url)

        if feed.bozo and not feed.entries:
            print(f"   âš ï¸  {name}: í”¼ë“œ íŒŒì‹± ì˜¤ë¥˜")
            return []

        entries = []
        cutoff_date = datetime.now() - timedelta(days=days)

        for entry in feed.entries:
            pub_date = parse_date(entry)

            # ë‚ ì§œ í•„í„°ë§
            if pub_date and pub_date < cutoff_date:
                continue

            title = entry.get("title", "Untitled")
            link = entry.get("link", "")
            summary = entry.get("summary", "")

            # summary ì •ë¦¬ (HTML íƒœê·¸ ì œê±°)
            import re
            summary = re.sub(r"<[^>]+>", "", summary)
            summary = re.sub(r"\s+", " ", summary).strip()
            if len(summary) > 300:
                summary = summary[:300] + "..."

            entries.append({
                "title": title,
                "link": link,
                "summary": summary,
                "published": pub_date.strftime("%Y-%m-%d %H:%M") if pub_date else "",
                "feed_name": name,
                "category": category,
            })

        return entries

    except Exception as e:
        print(f"   âš ï¸  {name}: {e}")
        return []


def collect_all_feeds(feeds: list[dict], days: int = 7) -> dict[str, list[dict]]:
    """ëª¨ë“  í”¼ë“œ ìˆ˜ì§‘ ë° ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹í™”"""
    all_entries = []

    for feed in feeds:
        name = feed.get("name", feed.get("url", "Unknown"))
        print(f"   ğŸ“¡ ìˆ˜ì§‘ ì¤‘: {name}")
        entries = fetch_feed(feed, days)
        all_entries.extend(entries)
        print(f"      â†’ {len(entries)}ê°œ í•­ëª©")

    # ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹í™”
    by_category = {}
    for entry in all_entries:
        cat = entry.get("category", "general")
        if cat not in by_category:
            by_category[cat] = []
        by_category[cat].append(entry)

    # ê° ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹  ë¨¼ì €)
    for cat in by_category:
        by_category[cat].sort(key=lambda x: x.get("published", ""), reverse=True)

    return by_category


def build_reading_note(categorized: dict[str, list[dict]], days: int) -> str:
    """ì½ê¸° ëª©ë¡ ë…¸íŠ¸ ìƒì„±"""
    today = datetime.now().strftime("%Y-%m-%d")

    lines = [
        f"# RSS í”¼ë“œ - {today}",
        "",
        f"> ìµœê·¼ {days}ì¼ê°„ ìˆ˜ì§‘ëœ ê¸€",
        "",
    ]

    total = sum(len(entries) for entries in categorized.values())
    lines.append(f"ì´ {total}ê°œ í•­ëª©")
    lines.append("")

    # ì¹´í…Œê³ ë¦¬ ì´ëª¨ì§€ ë§¤í•‘
    category_emoji = {
        "tech": "ğŸ’»",
        "dev": "ğŸ› ï¸",
        "news": "ğŸ“°",
        "ai": "ğŸ¤–",
        "cloud": "â˜ï¸",
        "security": "ğŸ”’",
        "design": "ğŸ¨",
        "general": "ğŸ“Œ",
    }

    for category, entries in sorted(categorized.items()):
        emoji = category_emoji.get(category, "ğŸ“Œ")
        lines.append(f"## {emoji} {category.title()}")
        lines.append("")

        for entry in entries[:10]:  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 10ê°œ
            title = entry.get("title", "Untitled")
            link = entry.get("link", "")
            summary = entry.get("summary", "")
            published = entry.get("published", "")
            feed_name = entry.get("feed_name", "")

            lines.append(f"### [{title}]({link})")
            lines.append(f"- ì¶œì²˜: {feed_name}")
            if published:
                lines.append(f"- ë‚ ì§œ: {published}")
            if summary:
                lines.append(f"- {summary}")
            lines.append("")

        if len(entries) > 10:
            lines.append(f"_...ì™¸ {len(entries) - 10}ê°œ_")
            lines.append("")

    return "\n".join(lines)


def get_reading_folder_path() -> Path:
    """ì½ê¸° ëª©ë¡ í´ë” ê²½ë¡œ"""
    vault_path = Path(CONFIG["vault"]["path"]).expanduser()
    return vault_path / "reading"


def get_existing_links() -> set[str]:
    """Obsidian reading í´ë”ì—ì„œ ê¸°ì¡´ ê¸€ ë§í¬ë“¤ ì¶”ì¶œ"""
    import re

    reading_folder = get_reading_folder_path()
    if not reading_folder.exists():
        return set()

    existing_links = set()

    for md_file in reading_folder.glob("*.md"):
        try:
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read()

            # ë§ˆí¬ë‹¤ìš´ ë§í¬ ì¶”ì¶œ: [title](url) ë˜ëŠ” <url>
            # í—¤ë” ë§í¬ íŒ¨í„´: ### [title](url)
            links = re.findall(r'\[.*?\]\((https?://[^\)]+)\)', content)
            existing_links.update(links)

        except Exception:
            pass

    return existing_links


def filter_existing_entries(
    categorized: dict[str, list[dict]],
    existing_links: set[str]
) -> tuple[dict[str, list[dict]], int]:
    """ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê¸€ í•„í„°ë§

    Returns:
        (í•„í„°ë§ëœ ê²°ê³¼, ê±´ë„ˆë›´ ê°œìˆ˜)
    """
    filtered = {}
    skipped_count = 0

    for category, entries in categorized.items():
        filtered_entries = []
        for entry in entries:
            link = entry.get("link", "")
            # URL ì •ê·œí™” (trailing slash ë“±)
            normalized_link = link.rstrip("/")

            # ê¸°ì¡´ ë§í¬ì— ìˆëŠ”ì§€ í™•ì¸
            if any(normalized_link in existing or existing in normalized_link
                   for existing in existing_links):
                skipped_count += 1
            else:
                filtered_entries.append(entry)

        if filtered_entries:
            filtered[category] = filtered_entries

    return filtered, skipped_count


def save_reading_note(content: str, target_date: str) -> str:
    """ì½ê¸° ëª©ë¡ ë…¸íŠ¸ ì €ì¥"""
    reading_folder = get_reading_folder_path()
    reading_folder.mkdir(parents=True, exist_ok=True)

    note_path = reading_folder / f"{target_date}_rss.md"

    with open(note_path, "w", encoding="utf-8") as f:
        f.write(content)

    return str(note_path)


def send_slack_notification(categorized: dict[str, list[dict]]) -> bool:
    """Slackìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡"""
    webhook_url = os.environ.get("SLACK_WEBHOOK_URL")

    if not webhook_url:
        print("âš ï¸  SLACK_WEBHOOK_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False

    total = sum(len(entries) for entries in categorized.values())
    if total == 0:
        return True

    blocks = [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": f"ğŸ“° RSS í”¼ë“œ ìˆ˜ì§‘ ({total}ê°œ)",
                "emoji": True
            }
        },
        {"type": "divider"},
    ]

    # ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½
    for category, entries in sorted(categorized.items()):
        if entries:
            # ìµœì‹  3ê°œë§Œ í‘œì‹œ
            sample_titles = [e["title"][:50] for e in entries[:3]]
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*{category.title()}* ({len(entries)}ê°œ)\n" +
                            "\n".join([f"â€¢ {t}" for t in sample_titles])
                }
            })

    payload = {"blocks": blocks}

    try:
        data = json.dumps(payload).encode("utf-8")
        request = urllib.request.Request(
            webhook_url,
            data=data,
            headers={"Content-Type": "application/json"}
        )
        with urllib.request.urlopen(request, timeout=10) as response:
            return response.status == 200
    except Exception as e:
        print(f"âš ï¸  Slack ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
        return False


def print_summary(categorized: dict[str, list[dict]]):
    """ì½˜ì†”ì— ìš”ì•½ ì¶œë ¥"""
    print("\n" + "â”" * 50)
    print("ğŸ“° RSS í”¼ë“œ ìˆ˜ì§‘ ê²°ê³¼")
    print("â”" * 50)

    total = sum(len(entries) for entries in categorized.values())
    if total == 0:
        print("ìˆ˜ì§‘ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ì´ {total}ê°œ í•­ëª©")
    print("")

    for category, entries in sorted(categorized.items()):
        if entries:
            print(f"{category.title()}: {len(entries)}ê°œ")
            for entry in entries[:3]:
                title = entry.get("title", "")[:50]
                print(f"  - {title}")
            if len(entries) > 3:
                print(f"  - ...ì™¸ {len(entries) - 3}ê°œ")
            print("")

    print("â”" * 50)


def main():
    # ì˜µì…˜ íŒŒì‹±
    args = sys.argv[1:]

    yes_mode = False
    slack_mode = False
    days = 7
    feed_urls = None  # --feeds ì˜µì…˜ìœ¼ë¡œ ì „ë‹¬ëœ URLë“¤
    skip_existing = None  # Noneì´ë©´ ì„¤ì • íŒŒì¼ì—ì„œ ê²°ì •

    i = 0
    while i < len(args):
        arg = args[i]
        if arg in ("--yes", "-y"):
            yes_mode = True
            i += 1
        elif arg == "--slack":
            slack_mode = True
            i += 1
        elif arg == "--days" and i + 1 < len(args):
            days = int(args[i + 1])
            i += 2
        elif arg == "--feeds" and i + 1 < len(args):
            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ URL íŒŒì‹±
            feed_urls = [url.strip() for url in args[i + 1].split(",") if url.strip()]
            i += 2
        elif arg == "--skip-existing":
            skip_existing = True
            i += 1
        elif arg == "--no-skip":
            skip_existing = False
            i += 1
        else:
            i += 1

    # skip_existing ê²°ì •: CLI ì˜µì…˜ > ì„¤ì • íŒŒì¼ > ê¸°ë³¸ê°’(False)
    if skip_existing is None:
        rss_config = get_rss_config()
        skip_existing = rss_config.get("skip_existing", False)

    today = datetime.now().strftime("%Y-%m-%d")

    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"ğŸ“° RSS Feed Collector: {today}")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"   ìˆ˜ì§‘ ë²”ìœ„: ìµœê·¼ {days}ì¼")
    print(f"   ì¤‘ë³µ ë°©ì§€: {'âœ… í™œì„±í™”' if skip_existing else 'âŒ ë¹„í™œì„±í™”'}")
    if feed_urls:
        print(f"   ì†ŒìŠ¤: ì˜µì…˜ ì§€ì • ({len(feed_urls)}ê°œ URL)")

    # í”¼ë“œ ëª©ë¡ ì¡°íšŒ
    feeds = get_feeds(override_urls=feed_urls)
    if not feeds:
        return

    print(f"   ë“±ë¡ëœ í”¼ë“œ: {len(feeds)}ê°œ")
    print("")

    # í”¼ë“œ ìˆ˜ì§‘
    print("ğŸ“¡ í”¼ë“œ ìˆ˜ì§‘ ì¤‘...")
    categorized = collect_all_feeds(feeds, days)

    # ì¤‘ë³µ í•„í„°ë§
    skipped_count = 0
    if skip_existing:
        print("\nğŸ” ì¤‘ë³µ í™•ì¸ ì¤‘...")
        existing_links = get_existing_links()
        print(f"   ê¸°ì¡´ ë§í¬: {len(existing_links)}ê°œ")
        categorized, skipped_count = filter_existing_entries(categorized, existing_links)
        if skipped_count > 0:
            print(f"   â­ï¸  ì¤‘ë³µ ê±´ë„ˆëœ€: {skipped_count}ê°œ")

    # ì½˜ì†” ì¶œë ¥
    print_summary(categorized)

    total = sum(len(entries) for entries in categorized.values())
    if total == 0:
        print("\nğŸ“­ ìˆ˜ì§‘ëœ ìƒˆ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë…¸íŠ¸ ìƒì„±
    note_content = build_reading_note(categorized, days)

    # ë¯¸ë¦¬ë³´ê¸°
    print("\nğŸ“‹ Obsidian ë…¸íŠ¸ ë¯¸ë¦¬ë³´ê¸°")
    print("â”" * 40)
    preview = note_content[:500]
    if len(note_content) > 500:
        preview += "\n..."
    print(preview)
    print("â”" * 40)

    # ì €ì¥
    if yes_mode:
        choice = "y"
    else:
        try:
            choice = input("\nObsidianì— ì €ì¥í• ê¹Œìš”? [Y/n]: ").strip().lower()
        except EOFError:
            choice = "y"

    if choice in ["", "y", "yes"]:
        result_path = save_reading_note(note_content, today)
        print(f"\nâœ… ì €ì¥ ì™„ë£Œ!")
        print(f"   {result_path}")
    else:
        print("\nâ­ï¸  ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")

    # Slack ì•Œë¦¼
    if slack_mode:
        print("\nğŸ“¤ Slack ì•Œë¦¼ ì „ì†¡ ì¤‘...")
        if send_slack_notification(categorized):
            print("âœ… Slack ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ!")
        else:
            print("âŒ Slack ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")


if __name__ == "__main__":
    main()
