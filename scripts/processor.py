#!/usr/bin/env python3
"""
AI Pipeline - Knowledge Processor
=================================
CLI AI ì„¸ì…˜ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ Obsidian Vaultì— ì €ì¥í•˜ëŠ” ETL ìŠ¤í¬ë¦½íŠ¸

Usage:
    python processor.py <log_file_path>
    python processor.py --test  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
"""

import os
import sys
import json
import yaml
import re
import shutil
from pathlib import Path
from datetime import datetime
from typing import Optional
from dataclasses import dataclass

# === TTY Input Helper ===
# script ëª…ë ¹ì–´ ë“±ìœ¼ë¡œ stdinì´ ë¶„ë¦¬ëœ ê²½ìš°ì—ë„ í„°ë¯¸ë„ì—ì„œ ì…ë ¥ë°›ê¸° ìœ„í•¨

def tty_input(prompt: str = "") -> str:
    """í„°ë¯¸ë„ì—ì„œ ì§ì ‘ ì…ë ¥ë°›ê¸° (stdinì´ íŒŒì´í”„ì—¬ë„ ë™ì‘)"""
    try:
        # ë¨¼ì € /dev/tty ì‹œë„ (í„°ë¯¸ë„ ì§ì ‘ ì ‘ê·¼)
        with open("/dev/tty", "r") as tty:
            if prompt:
                print(prompt, end="", flush=True)
            return tty.readline().strip()
    except (OSError, FileNotFoundError):
        # /dev/tty ì—†ìœ¼ë©´ ì¼ë°˜ input ì‚¬ìš©
        return input(prompt)


# === Configuration ===

CONFIG_PATH = Path(__file__).parent.parent / "config" / "settings.yaml"


def load_config() -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


CONFIG = load_config()

RAW_LOG_DATE_RE = re.compile(r"(20\d{2})[^\d]?(\d{2})[^\d]?(\d{2})")
PROMPT_BLOCK_RE = re.compile(r"(?m)^[ \t]*[â¯â€º>]\s*(.+?)(?=^[ \t]*[â¯â€º>]\s*|\Z)", re.DOTALL)

NOISE_SUBSTRINGS = [
    "contet left",
    "skills to list available skills",
    "for shortcuts",
    "esc to interrupt",
    "working(",
    "planning",
    "preparing",
    "exploring",
    "loading",
    "no matches",
    "initialized",
    "gradle",
    "daemon",
    "executing tests",
    "eecuting tests",
    "run with --scan",
]


def _get_raw_logs_root() -> Optional[Path]:
    raw_dir = CONFIG.get("pipeline", {}).get("raw_logs_dir")
    if not raw_dir:
        return None
    return Path(os.path.expandvars(os.path.expanduser(raw_dir)))


def _infer_log_date_from_name(filename: str) -> Optional[datetime]:
    match = RAW_LOG_DATE_RE.search(filename)
    if not match:
        return None
    try:
        return datetime(int(match.group(1)), int(match.group(2)), int(match.group(3)))
    except ValueError:
        return None


def _is_relative_to(path: Path, base: Path) -> bool:
    try:
        path.relative_to(base)
        return True
    except ValueError:
        return False


def resolve_log_path(log_path: str) -> Path:
    """ë¡œê·¸ ê²½ë¡œ í•´ì„ (raw_logs_dir ë° ë‚ ì§œ í´ë” ì§€ì›)"""
    path = Path(log_path).expanduser()
    if path.exists():
        return path

    raw_root = _get_raw_logs_root()
    if not raw_root:
        return path

    candidate = raw_root / path
    if candidate.exists():
        return candidate

    log_date = _infer_log_date_from_name(path.name)
    if log_date:
        dated = raw_root / log_date.strftime("%Y") / log_date.strftime("%m") / log_date.strftime("%d") / path.name
        if dated.exists():
            return dated

    return path


def organize_raw_log(log_path: Path) -> Path:
    """raw ë¡œê·¸ë¥¼ YYYY/MM/DD í´ë”ë¡œ ì´ë™"""
    raw_root = _get_raw_logs_root()
    if not raw_root:
        return log_path

    try:
        resolved_path = log_path.resolve()
        raw_root_resolved = raw_root.resolve()
    except FileNotFoundError:
        return log_path

    if not _is_relative_to(resolved_path, raw_root_resolved):
        return log_path

    rel_parts = resolved_path.relative_to(raw_root_resolved).parts
    if (
        len(rel_parts) >= 4
        and re.fullmatch(r"\d{4}", rel_parts[0])
        and re.fullmatch(r"\d{2}", rel_parts[1])
        and re.fullmatch(r"\d{2}", rel_parts[2])
    ):
        return log_path

    log_date = _infer_log_date_from_name(log_path.name)
    if not log_date:
        try:
            log_date = datetime.fromtimestamp(log_path.stat().st_mtime)
        except OSError:
            return log_path

    dest_dir = raw_root_resolved / log_date.strftime("%Y") / log_date.strftime("%m") / log_date.strftime("%d")
    dest_dir.mkdir(parents=True, exist_ok=True)

    dest_path = dest_dir / log_path.name
    counter = 1
    while dest_path.exists():
        dest_path = dest_dir / f"{log_path.stem}_{counter}{log_path.suffix}"
        counter += 1

    try:
        shutil.move(str(log_path), str(dest_path))
    except OSError:
        return log_path

    print(f"       - raw ë¡œê·¸ ì´ë™: {dest_path}")
    return dest_path


# === Data Classes ===

@dataclass
class VaultContext:
    """Vault ì»¨í…ìŠ¤íŠ¸ ì •ë³´"""
    folders: list[str]
    files: list[str]
    tags: set[str]


@dataclass
class ProcessingDecision:
    """LLMì˜ ì²˜ë¦¬ ê²°ì •"""
    action: str  # "new" | "append" | "link"
    target_folder: str
    target_file: Optional[str]
    title: str
    tags: list[str]
    summary: str
    related_files: list[str]
    content: str


# === Vault Scanner ===

def scan_vault() -> VaultContext:
    """Obsidian Vault êµ¬ì¡° ìŠ¤ìº”"""
    vault_path = Path(CONFIG["vault"]["path"])
    target_folder = CONFIG["vault"]["target_folder"]
    target_path = vault_path / target_folder

    folders = []
    files = []
    tags = set()

    for root, dirs, filenames in os.walk(target_path):
        # ìˆ¨ê¹€ í´ë” ì œì™¸
        dirs[:] = [d for d in dirs if not d.startswith(".")]

        rel_path = Path(root).relative_to(target_path)
        if str(rel_path) != ".":
            folders.append(str(rel_path))

        for filename in filenames:
            if filename.endswith(".md"):
                file_path = Path(root) / filename
                files.append(str(file_path.relative_to(target_path)))

                # íŒŒì¼ì—ì„œ íƒœê·¸ ì¶”ì¶œ
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()
                        # YAML frontmatterì—ì„œ íƒœê·¸ ì¶”ì¶œ
                        if content.startswith("---"):
                            end = content.find("---", 3)
                            if end != -1:
                                frontmatter = content[3:end]
                                if "tags:" in frontmatter:
                                    tag_match = re.findall(r"#?([\w-]+)", frontmatter.split("tags:")[1].split("\n")[0])
                                    tags.update(tag_match)
                        # ë³¸ë¬¸ì—ì„œ íƒœê·¸ ì¶”ì¶œ
                        inline_tags = re.findall(r"#([\w-]+)", content)
                        tags.update(inline_tags)
                except Exception:
                    pass

    return VaultContext(folders=folders, files=files, tags=tags)


# === LLM Clients ===

def get_llm_client():
    """ì„¤ì •ì— ë”°ë¥¸ LLM í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    provider = CONFIG["llm"]["provider"]

    if provider == "gemini":
        return GeminiClient()
    elif provider == "openai":
        return OpenAIClient()
    elif provider == "anthropic":
        return AnthropicClient()
    else:
        raise ValueError(f"Unknown LLM provider: {provider}")


class GeminiClient:
    """Google Gemini API í´ë¼ì´ì–¸íŠ¸ (google.genai íŒ¨í‚¤ì§€ ì‚¬ìš©)

    ì¥ì :
    - 2M tokens context window (4.5MB ë¡œê·¸ë„ í•œë²ˆì— ì²˜ë¦¬ ê°€ëŠ¥)
    - ê°€ì¥ ì €ë ´í•œ ë¹„ìš©
    """

    def __init__(self):
        try:
            from google import genai

            api_key = os.environ.get("GOOGLE_API_KEY")
            if not api_key:
                print("GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                sys.exit(1)

            self.client = genai.Client(api_key=api_key)
            self.model_name = CONFIG["llm"]["gemini"]["model"]
        except ImportError:
            print("google-genai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("pip install google-genai")
            sys.exit(1)

    def analyze(self, log_content: str, vault_context: VaultContext) -> ProcessingDecision:
        """ë¡œê·¸ ë¶„ì„ ë° ì²˜ë¦¬ ê²°ì •

        GeminiëŠ” 2M contextë¥¼ ì§€ì›í•˜ë¯€ë¡œ ì „ì²´ ë¡œê·¸ë¥¼ ë³´ë‚¼ ìˆ˜ ìˆìŒ
        """
        from google.genai import types

        prompt = self._build_prompt(log_content, vault_context)

        # Gemini API í˜¸ì¶œ
        response = self.client.models.generate_content(
            model=self.model_name,
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.3,
                response_mime_type="application/json"
            )
        )

        result = json.loads(response.text)

        # ì‘ë‹µì´ listì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
        if isinstance(result, list):
            result = result[0] if result else {}

        return self._parse_decision(result)

    def _build_prompt(self, log_content: str, vault_context: VaultContext) -> str:
        # GeminiëŠ” 1M context ì§€ì› â†’ ì „ì²´ ë¡œê·¸ ì „ì†¡ ê°€ëŠ¥ (ìµœëŒ€ 500Kì)
        max_chars = 500000  # ì•½ 500KB, ì¶©ë¶„í•œ ì—¬ìœ 
        content_to_send = log_content[:max_chars] if len(log_content) > max_chars else log_content

        return f"""{SYSTEM_PROMPT}

## Vault êµ¬ì¡°
í´ë”: {vault_context.folders[:20]}
ê¸°ì¡´ íŒŒì¼: {vault_context.files[:30]}
ê¸°ì¡´ íƒœê·¸: {list(vault_context.tags)[:30]}

## ì„¸ì…˜ ë¡œê·¸
```
{content_to_send}
```

ìœ„ ì„¸ì…˜ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

### ì¶œë ¥ í’ˆì§ˆ ê°€ì´ë“œ
- ìš”ì•½ì€ 2~4ë¬¸ì¥, ë§¥ë½/ì˜ì‚¬ê²°ì •/ê·¼ê±° í¬í•¨
- ë³¸ë¬¸ì€ "í•µì‹¬ ë‚´ìš© â†’ ê·¼ê±°/ì˜ˆì‹œ â†’ ì •ë¦¬" ìˆœì„œë¡œ êµ¬ì¡°í™”
- ë¡œê·¸ê°€ ì§€ì €ë¶„í•´ë„ ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ë§Œ ë½‘ì•„ì„œ ì •ë¦¬"""

    def _parse_decision(self, result: dict) -> ProcessingDecision:
        return ProcessingDecision(
            action=result.get("action", "new"),
            target_folder=result.get("target_folder", "Inbox"),
            target_file=result.get("target_file"),
            title=result.get("title", "Untitled"),
            tags=result.get("tags", []),
            summary=result.get("summary", ""),
            related_files=result.get("related_files", []),
            content=result.get("content", "")
        )


class OpenAIClient:
    """OpenAI API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self):
        try:
            from openai import OpenAI
            self.client = OpenAI()  # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
            self.model = CONFIG["llm"]["openai"]["model"]
        except ImportError:
            print("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai")
            sys.exit(1)

    def analyze(self, log_content: str, vault_context: VaultContext) -> ProcessingDecision:
        """ë¡œê·¸ ë¶„ì„ ë° ì²˜ë¦¬ ê²°ì •"""
        prompt = self._build_prompt(log_content, vault_context)

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.3
        )

        result = json.loads(response.choices[0].message.content)
        return self._parse_decision(result)

    def _build_prompt(self, log_content: str, vault_context: VaultContext) -> str:
        # ì´ë¯¸ ì¶”ì¶œëœ ëŒ€í™”ì´ë¯€ë¡œ ìµœëŒ€ 16000ì ì‚¬ìš©
        content_to_send = log_content[:16000] if len(log_content) > 16000 else log_content
        return f"""## Vault êµ¬ì¡°
í´ë”: {vault_context.folders[:20]}
ê¸°ì¡´ íŒŒì¼: {vault_context.files[:30]}
ê¸°ì¡´ íƒœê·¸: {list(vault_context.tags)[:30]}

## ì„¸ì…˜ ë¡œê·¸ (í•µì‹¬ ëŒ€í™”)
```
{content_to_send}
```

ìœ„ ì„¸ì…˜ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

### ì¶œë ¥ í’ˆì§ˆ ê°€ì´ë“œ
- ìš”ì•½ì€ 2~4ë¬¸ì¥, ë§¥ë½/ì˜ì‚¬ê²°ì •/ê·¼ê±° í¬í•¨
- ë³¸ë¬¸ì€ "í•µì‹¬ ë‚´ìš© â†’ ê·¼ê±°/ì˜ˆì‹œ â†’ ì •ë¦¬" ìˆœì„œë¡œ êµ¬ì¡°í™”
- ë¡œê·¸ê°€ ì§€ì €ë¶„í•´ë„ ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ë§Œ ë½‘ì•„ì„œ ì •ë¦¬"""

    def _parse_decision(self, result: dict) -> ProcessingDecision:
        return ProcessingDecision(
            action=result.get("action", "new"),
            target_folder=result.get("target_folder", "Inbox"),
            target_file=result.get("target_file"),
            title=result.get("title", "Untitled"),
            tags=result.get("tags", []),
            summary=result.get("summary", ""),
            related_files=result.get("related_files", []),
            content=result.get("content", "")
        )


class AnthropicClient:
    """Anthropic API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self):
        try:
            import anthropic
            self.client = anthropic.Anthropic()  # ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
            self.model = CONFIG["llm"]["anthropic"]["model"]
        except ImportError:
            print("anthropic íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install anthropic")
            sys.exit(1)

    def analyze(self, log_content: str, vault_context: VaultContext) -> ProcessingDecision:
        """ë¡œê·¸ ë¶„ì„ ë° ì²˜ë¦¬ ê²°ì •"""
        prompt = self._build_prompt(log_content, vault_context)

        response = self.client.messages.create(
            model=self.model,
            max_tokens=4096,
            system=SYSTEM_PROMPT,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )

        # JSON ì¶”ì¶œ
        content = response.content[0].text
        json_match = re.search(r"\{[\s\S]*\}", content)
        if json_match:
            result = json.loads(json_match.group())
            return self._parse_decision(result)
        else:
            raise ValueError("LLM ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def _build_prompt(self, log_content: str, vault_context: VaultContext) -> str:
        # ì´ë¯¸ ì¶”ì¶œëœ ëŒ€í™”ì´ë¯€ë¡œ ìµœëŒ€ 16000ì ì‚¬ìš©
        content_to_send = log_content[:16000] if len(log_content) > 16000 else log_content
        return f"""## Vault êµ¬ì¡°
í´ë”: {vault_context.folders[:20]}
ê¸°ì¡´ íŒŒì¼: {vault_context.files[:30]}
ê¸°ì¡´ íƒœê·¸: {list(vault_context.tags)[:30]}

## ì„¸ì…˜ ë¡œê·¸ (ë§ˆì§€ë§‰ ëŒ€í™”)
```
{content_to_send}
```

ìœ„ ì„¸ì…˜ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

    def _parse_decision(self, result: dict) -> ProcessingDecision:
        return ProcessingDecision(
            action=result.get("action", "new"),
            target_folder=result.get("target_folder", "Inbox"),
            target_file=result.get("target_file"),
            title=result.get("title", "Untitled"),
            tags=result.get("tags", []),
            summary=result.get("summary", ""),
            related_files=result.get("related_files", []),
            content=result.get("content", "")
        )


# === System Prompt ===

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ê°œë°œìì˜ AI ëŒ€í™” ì„¸ì…˜ì„ ë¶„ì„í•˜ì—¬ ì§€ì‹ ë² ì´ìŠ¤(Obsidian)ì— ì €ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì—­í• 
1. ì„¸ì…˜ ë¡œê·¸ì—ì„œ í•µì‹¬ ì§€ì‹/í•™ìŠµ ë‚´ìš© ì¶”ì¶œ
2. ê¸°ì¡´ Vault êµ¬ì¡°ì™€ ë¹„êµí•˜ì—¬ ìµœì ì˜ ì €ì¥ ìœ„ì¹˜ ê²°ì •
3. ì ì ˆí•œ íƒœê·¸ì™€ ì—°ê´€ ë¬¸ì„œ ì‹ë³„

## ì›ì¹™
- UI ì¡ìŒ/ë°˜ë³µ í…ìŠ¤íŠ¸/ë¡œê·¸ ë©”íƒ€ëŠ” ë¬´ì‹œí•˜ê³ , ì‹¤ì œ ëŒ€í™”ë§Œ ë°˜ì˜
- ì‚¬ìš©ìê°€ ì§€ì‹œí•œ ì‚¬í•­ê³¼ ê²°ì •ëœ ê²°ë¡  ì—­ì‹œ ì •ë¦¬
- ê³¼ì¥ ê¸ˆì§€: ë¡œê·¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ ê²ƒ
- í•„ìš”í•œ ê²½ìš° "ì¶”ì •"ì´ ì•„ë‹Œ "ì§ˆë¬¸/ì—´ë¦° í•­ëª©"ìœ¼ë¡œ ë‚¨ê¸¸ ê²ƒ

## ì‘ë‹µ í˜•ì‹ (JSON)
{
    "action": "new" | "append",
    "target_folder": "ì €ì¥í•  í´ë”ëª… (ì˜ˆ: Docker, Java, AI)",
    "target_file": "appendì¼ ê²½ìš° ê¸°ì¡´ íŒŒì¼ ê²½ë¡œ, newì¼ ê²½ìš° null",
    "title": "ë¬¸ì„œ ì œëª© (ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ)",
    "tags": ["tag1", "tag2"],
    "summary": "2-3ë¬¸ì¥ ìš”ì•½",
    "related_files": ["ì—°ê´€ëœ ê¸°ì¡´ íŒŒì¼ëª…"],
    "content": "Markdown í˜•ì‹ì˜ ë³¸ë¬¸ ë‚´ìš©"
}

## ë¶„ë¥˜ ê¸°ì¤€
- Docker, container ê´€ë ¨ â†’ Docker í´ë”
- Java, Spring, JPA ê´€ë ¨ â†’ Java í´ë”
- Kafka, ë©”ì‹œì§€ í ê´€ë ¨ â†’ kafka í´ë”
- AWS, í´ë¼ìš°ë“œ ê´€ë ¨ â†’ aws í´ë”
- ë¶„ë¥˜ ë¶ˆí™•ì‹¤ â†’ Inbox í´ë”

## ì£¼ì˜ì‚¬í•­
- ì½”ë“œ ë¸”ë¡ì€ ì–¸ì–´ ëª…ì‹œ (```java, ```python ë“±)
- ê¸°ì¡´ ë¬¸ì„œì™€ ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ append ê¶Œì¥
- íƒœê·¸ëŠ” ê¸°ì¡´ íƒœê·¸ ì¬ì‚¬ìš© ìš°ì„ 
- í•„ìš”í•˜ë‹¤ë©´, íƒœê·¸ ë° í´ë”ë¥¼ ì¶”ê°€
- ë¶ˆí•„ìš”í•œ ëŒ€í™”(ì¸ì‚¬, í™•ì¸ ë“±)ëŠ” ì œì™¸
- ì •ë³´ ì†ì‹¤ì€ ìµœì†Œí™”, ëŒ€í™”ê°€ ê¸¸ê³ , ì¤‘ìš”í•œ ë‚´ìš©ë“¤ì´ ìˆë‹¤ë©´ ê¸¸ê³  ìì„¸íˆ í¬í•¨"""


# === File Writer ===

def write_to_vault(
    decision: ProcessingDecision,
    raw_log_path: Optional[Path] = None,
) -> str:
    """ê²°ì •ì— ë”°ë¼ Vaultì˜ _drafts í´ë”ì— íŒŒì¼ ì‘ì„±

    ëª¨ë“  ìƒˆ ë…¸íŠ¸ëŠ” _drafts/ì— ë¨¼ì € ì €ì¥ë¨ (staging)
    íŒŒì¼ëª…: YYYY-MM-DD_ì œëª©.md
    """
    vault_path = Path(CONFIG["vault"]["path"])
    drafts_folder = CONFIG["vault"].get("drafts_folder", "study/_drafts")

    # drafts í´ë” ìƒì„±
    folder_path = vault_path / drafts_folder
    folder_path.mkdir(parents=True, exist_ok=True)

    # íŒŒì¼ëª… ìƒì„±: ë‚ ì§œ_ì œëª©.md
    date_prefix = datetime.now().strftime('%Y-%m-%d')
    safe_title = re.sub(r'[\\/*?:"<>|]', "", decision.title)
    safe_title = safe_title.replace(' ', '-')[:50]  # ê³µë°±â†’í•˜ì´í”ˆ, 50ì ì œí•œ
    file_path = folder_path / f"{date_prefix}_{safe_title}.md"

    # ì¤‘ë³µ íŒŒì¼ëª… ì²˜ë¦¬
    counter = 1
    while file_path.exists():
        file_path = folder_path / f"{date_prefix}_{safe_title}_{counter}.md"
        counter += 1

    # íƒœê·¸ì— ë¶„ë¥˜ í´ë”ë„ ì¶”ê°€ (ë‚˜ì¤‘ì— promoteí•  ë•Œ ì‚¬ìš©)
    all_tags = list(decision.tags)
    if decision.target_folder and decision.target_folder not in all_tags:
        all_tags.insert(0, decision.target_folder.lower())

    tags_str = ", ".join([f"{tag}" for tag in all_tags])
    related_str = ", ".join([f"[[{f}]]" for f in decision.related_files])

    # Frontmatter + Content ì‘ì„±
    raw_log_value = str(raw_log_path) if raw_log_path else ""
    content = f"""---
title: {decision.title}
tags: [{tags_str}]
date: {datetime.now().strftime('%Y-%m-%d')}
category: {decision.target_folder}
status: draft
related: [{related_str}]
source: ai-session
raw_log: {raw_log_value}
---

## Summary
{decision.summary}

---
{decision.content}
"""

    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)

    return str(file_path)


# === Log Parser ===

def extract_conversations(log_content: str) -> list[dict]:
    """ë¡œê·¸ì—ì„œ ëŒ€í™” ì„¸ì…˜ë“¤ì„ ì¶”ì¶œ

    Claude CLI ë¡œê·¸ í˜•ì‹:
    - "â¯" ë˜ëŠ” ">" ë¡œ ì‚¬ìš©ì ì…ë ¥ ì‹œì‘
    - Claude ì‘ë‹µì´ ë’¤ë”°ë¦„
    """
    log_content = normalize_log_content(log_content)

    conversations = []

    matches = PROMPT_BLOCK_RE.findall(log_content)

    for match in matches:
        content = match.strip()
        if len(content) > 80:  # ë„ˆë¬´ ì§§ì€ ëŒ€í™” ì œì™¸
            lines = content.split("\n")
            question = lines[0].strip() if lines else ""
            conversations.append(
                {
                    "question": question,
                    "content": content,
                }
            )

    return conversations


def get_main_conversation(log_content: str) -> str:
    """ë¡œê·¸ì—ì„œ ë©”ì¸ ëŒ€í™” ì¶”ì¶œ (ë§ˆì§€ë§‰ ì˜ë¯¸ìˆëŠ” ëŒ€í™”)"""
    conversations = extract_conversations(log_content)

    if not conversations:
        # ëŒ€í™” ì¶”ì¶œ ì‹¤íŒ¨ì‹œ ë§ˆì§€ë§‰ ë¶€ë¶„ ë°˜í™˜
        normalized = normalize_log_content(log_content)
        return normalized[-20000:] if len(normalized) > 20000 else normalized

    # ë§ˆì§€ë§‰ ëŒ€í™” (ê°€ì¥ ìµœê·¼)
    last_conv = conversations[-1]
    content = last_conv["content"]

    # ë„ˆë¬´ ê¸¸ë©´ ë§ˆì§€ë§‰ 20000ì
    if len(content) > 20000:
        content = content[-20000:]

    print(f"       - ì¶”ì¶œëœ ëŒ€í™”: \"{last_conv['question'][:50]}...\"")
    return content


def clean_ansi(content: str) -> str:
    """ANSI escape ì½”ë“œ ì œê±°"""
    content = re.sub(r'\x1b\[[0-9;]*m', '', content)
    content = re.sub(r'\x1b\[[0-9;]*[A-Za-z]', '', content)
    content = re.sub(r'\x1b\[[\d;]*[A-Za-z]', '', content)
    return content


def _is_noise_line(line: str) -> bool:
    stripped = line.strip()
    if not stripped:
        return True

    lower = stripped.lower()
    for token in NOISE_SUBSTRINGS:
        if token in lower:
            return True

    if stripped.startswith(("â€¢", "â””", "â•­", "â•°", "â•®", "â•¯")):
        return True

    if re.fullmatch(r"[â€¢\-\â”€\_\. ]{5,}", stripped):
        return True

    if len(stripped) >= 60 and len(set(stripped)) <= 8:
        return True

    return False


def normalize_log_content(content: str) -> str:
    """UI ë…¸ì´ì¦ˆ ì œê±° ë° ê¸°ë³¸ ì •ë¦¬"""
    cleaned = clean_ansi(content)
    lines = cleaned.splitlines()
    filtered = [line for line in lines if not _is_noise_line(line)]
    return "\n".join(filtered).strip()






# === Main Pipeline ===

def _build_prompt_preview(llm, provider: str, log_content: str, vault_context: VaultContext) -> str:
    """LLMì— ì „ë‹¬ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸° ìƒì„±"""
    if not hasattr(llm, "_build_prompt"):
        return ""
    user_prompt = llm._build_prompt(log_content, vault_context)
    if provider == "gemini":
        return user_prompt
    return f"{SYSTEM_PROMPT}\n\n---\n\n{user_prompt}"


def process_log(log_path: str, show_prompt: bool = False) -> str:
    """ë©”ì¸ íŒŒì´í”„ë¼ì¸: ë¡œê·¸ íŒŒì¼ ì²˜ë¦¬"""
    resolved_path = resolve_log_path(log_path)
    if not resolved_path.exists():
        print(f"âŒ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_path}")
        return ""

    organized_path = organize_raw_log(resolved_path)

    print(f"[1/4] ë¡œê·¸ íŒŒì¼ ë¡œë“œ: {organized_path}")
    with open(organized_path, "r", encoding="utf-8", errors="ignore") as f:
        raw_content = f.read()

    print(f"       - ì›ë³¸ í¬ê¸°: {len(raw_content):,} bytes")

    # LLM providerì— ë”°ë¼ ì²˜ë¦¬ ë°©ì‹ ê²°ì •
    provider = CONFIG["llm"]["provider"]

    if provider == "gemini":
        # Gemini: 1M context ì§€ì› â†’ ì „ì²´ ë¡œê·¸ ì‚¬ìš©
        log_content = normalize_log_content(raw_content)
        print(f"       - Gemini ëª¨ë“œ: ì „ì²´ ë¡œê·¸ ì‚¬ìš© ({len(log_content):,} bytes)")
    else:
        # OpenAI/Anthropic: context ì œí•œ â†’ ë§ˆì§€ë§‰ ëŒ€í™”ë§Œ ì¶”ì¶œ
        log_content = get_main_conversation(raw_content)
        print(f"       - ì¶”ì¶œ í¬ê¸°: {len(log_content):,} bytes")

    if len(log_content.strip()) < 100:
        print("[SKIP] ë¡œê·¸ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
        return ""

    print(f"[2/4] Vault ìŠ¤ìº” ì¤‘...")
    vault_context = scan_vault()
    print(f"       - í´ë”: {len(vault_context.folders)}ê°œ")
    print(f"       - íŒŒì¼: {len(vault_context.files)}ê°œ")
    print(f"       - íƒœê·¸: {len(vault_context.tags)}ê°œ")

    print(f"[3/4] LLM ë¶„ì„ ì¤‘... (provider: {provider})")
    llm = get_llm_client()

    if show_prompt:
        prompt_preview = _build_prompt_preview(llm, provider, log_content, vault_context)
        print("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("ğŸ§ª LLM Prompt Preview (dry-run)")
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
        print(prompt_preview)
        print("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        return ""

    decision = llm.analyze(log_content, vault_context)

    print(f"       - ì•¡ì…˜: {decision.action}")
    print(f"       - í´ë”: {decision.target_folder}")
    print(f"       - ì œëª©: {decision.title}")
    print(f"       - íƒœê·¸: {decision.tags}")

    # ì €ì¥ ì „ í™•ì¸ (interactive mode)
    decision = confirm_before_save(decision)
    if decision is None:
        print("\nâ­ï¸  ì €ì¥ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")
        return ""

    print(f"\n[4/4] Vaultì— ì €ì¥ ì¤‘...")
    saved_path = write_to_vault(
        decision,
        raw_log_path=organized_path,
    )
    print(f"       âœ“ ì €ì¥ ì™„ë£Œ: {saved_path}")

    return saved_path


def confirm_before_save(decision: ProcessingDecision) -> Optional[ProcessingDecision]:
    """ì €ì¥ ì „ í™•ì¸ ë° ìˆ˜ì • í”„ë¡¬í”„íŠ¸"""
    print("\n" + "â”" * 50)
    print("ğŸ“‹ ì €ì¥ ë¯¸ë¦¬ë³´ê¸°")
    print("â”" * 50)
    print(f"  ì œëª©: {decision.title}")
    print(f"  í´ë”: {decision.target_folder}/")
    print(f"  íƒœê·¸: {', '.join(['#' + t for t in decision.tags])}")
    print(f"  ì•¡ì…˜: {'ìƒˆ íŒŒì¼ ìƒì„±' if decision.action == 'new' else 'ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€'}")
    print("â”" * 50)
    print(f"\nğŸ“ ìš”ì•½:\n{decision.summary[:200]}...")
    print("\n" + "â”" * 50)

    while True:
        try:
            choice = tty_input("\nì €ì¥í• ê¹Œìš”? [Y/n/edit/show]: ").lower()
        except (EOFError, OSError):
            # Non-interactive mode (íŒŒì´í”„ ë“±)
            return decision

        if choice in ['', 'y', 'yes']:
            return decision

        elif choice in ['n', 'no', 'skip']:
            return None

        elif choice == 'edit':
            decision = edit_decision(decision)
            print("\nâœï¸  ìˆ˜ì •ë¨:")
            print(f"  ì œëª©: {decision.title}")
            print(f"  í´ë”: {decision.target_folder}/")
            print(f"  íƒœê·¸: {', '.join(['#' + t for t in decision.tags])}")

        elif choice == 'show':
            print("\nğŸ“„ ì „ì²´ ë‚´ìš©:")
            print("â”€" * 40)
            print(decision.content[:2000])
            if len(decision.content) > 2000:
                print(f"\n... ({len(decision.content) - 2000}ì ë” ìˆìŒ)")
            print("â”€" * 40)

        else:
            print("  [Y] ì €ì¥ | [n] ê±´ë„ˆë›°ê¸° | [edit] ìˆ˜ì • | [show] ë‚´ìš© ë³´ê¸°")


def edit_decision(decision: ProcessingDecision) -> ProcessingDecision:
    """ê²°ì • ìˆ˜ì • í”„ë¡¬í”„íŠ¸"""
    print("\nâœï¸  ìˆ˜ì • ëª¨ë“œ (Enterë¡œ í˜„ì¬ ê°’ ìœ ì§€)")

    # ì œëª© ìˆ˜ì •
    new_title = tty_input(f"  ì œëª© [{decision.title}]: ")
    if new_title:
        decision = ProcessingDecision(
            action=decision.action,
            target_folder=decision.target_folder,
            target_file=decision.target_file,
            title=new_title,
            tags=decision.tags,
            summary=decision.summary,
            related_files=decision.related_files,
            content=decision.content
        )

    # í´ë” ìˆ˜ì •
    print(f"  ì‚¬ìš© ê°€ëŠ¥í•œ í´ë”: AI, Docker, Java, kafka, aws, Redis, shell, Inbox, ...")
    new_folder = tty_input(f"  í´ë” [{decision.target_folder}]: ")
    if new_folder:
        decision = ProcessingDecision(
            action=decision.action,
            target_folder=new_folder,
            target_file=decision.target_file,
            title=decision.title,
            tags=decision.tags,
            summary=decision.summary,
            related_files=decision.related_files,
            content=decision.content
        )

    # íƒœê·¸ ìˆ˜ì •
    current_tags = ', '.join(decision.tags)
    new_tags = tty_input(f"  íƒœê·¸ [{current_tags}]: ")
    if new_tags:
        tags_list = [t.strip().lstrip('#') for t in new_tags.split(',')]
        decision = ProcessingDecision(
            action=decision.action,
            target_folder=decision.target_folder,
            target_file=decision.target_file,
            title=decision.title,
            tags=tags_list,
            summary=decision.summary,
            related_files=decision.related_files,
            content=decision.content
        )

    return decision


def test_mode():
    """í…ŒìŠ¤íŠ¸ ëª¨ë“œ: Vault ìŠ¤ìº” í…ŒìŠ¤íŠ¸"""
    print("=== Test Mode ===")
    print(f"Config path: {CONFIG_PATH}")
    print(f"Vault path: {CONFIG['vault']['path']}")

    vault_context = scan_vault()
    print(f"\ní´ë” ({len(vault_context.folders)}ê°œ):")
    for folder in vault_context.folders[:10]:
        print(f"  - {folder}")

    print(f"\níŒŒì¼ ({len(vault_context.files)}ê°œ):")
    for file in vault_context.files[:10]:
        print(f"  - {file}")

    print(f"\níƒœê·¸ ({len(vault_context.tags)}ê°œ):")
    print(f"  {list(vault_context.tags)[:20]}")


if __name__ == "__main__":
    args = sys.argv[1:]
    show_prompt = False
    if "--show-prompt" in args:
        show_prompt = True
        args = [a for a in args if a != "--show-prompt"]

    if len(args) < 1:
        print("Usage: python processor.py <log_file_path>")
        print("       python processor.py --test")
        print("       python processor.py --show-prompt <log_file_path>")
        sys.exit(1)

    if args[0] == "--test":
        test_mode()
    else:
        process_log(args[0], show_prompt=show_prompt)
